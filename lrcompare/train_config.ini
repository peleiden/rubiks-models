[DEFAULT]
rollouts = 1000
rollout_games = 1000
rollout_depth = 100
batch_size = 1000
evaluation_interval = 25
alpha_update = 0
update_interval = 25
tau = 1
lr = 1e-5
gamma = 1
reward_method = lapanfix

[ADAPTIVEHIGH]
lr = 1e-4
gamma = 0.9

[FIXEDLOW]
lr = 1e-6
gamma = 1

[ADAPTIVELOW]
lr = 1e-5
gamma = 0.95


# Run command
# runtrain.py --config configs/hpc_train.ini --location data/local_lrcompare

# Default configuration values at run
# {'alpha_update': '0',
#  'analysis': False,
#  'arch': 'fc',
#  'batch_size': '1000',
#  'evaluation_interval': '25',
#  'gamma': '1',
#  'is2024': True,
#  'location': 'data/local_train2020-06-01_21-21-49',
#  'lr': '1e-5',
#  'nn_init': 'glorot',
#  'optim_fn': 'RMSprop',
#  'reward_method': 'lapanfix',
#  'rollout_depth': '100',
#  'rollout_games': '1000',
#  'rollouts': '1000',
#  'tau': '1',
#  'update_interval': '25'}